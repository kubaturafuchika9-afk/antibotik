import os
import asyncio
import logging
import sys
import tempfile
from io import BytesIO
from typing import Optional, List, Dict

import uvicorn
from fastapi import FastAPI
import aiohttp
from PIL import Image

from aiogram import Bot, Dispatcher, types
from aiogram.enums import ParseMode
from aiogram.filters import CommandStart
from aiogram.types import Message
from aiogram.client.default import DefaultBotProperties

import google.generativeai as genai

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
TOKEN = os.getenv("TELEGRAM_TOKEN")
GOOGLE_KEYS = [
    os.getenv("GOOGLE_API_KEY"),
    os.getenv("GOOGLE_API_KEY_2"),
    os.getenv("GOOGLE_API_KEY_3"),
    os.getenv("GOOGLE_API_KEY_4"),
]
RENDER_URL = os.getenv("RENDER_EXTERNAL_URL")

# –£–±–∏—Ä–∞–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è
GOOGLE_KEYS = [k for k in GOOGLE_KEYS if k]

generation_config = {
    "temperature": 0.7,
    "top_p": 0.95,
    "top_k": 40,
    "max_output_tokens": 8192,
}

# --- –°–ò–°–¢–ï–ú–ù–´–ï –ü–†–û–ú–¢–´ ---
SYSTEM_PROMPT_DEFAULT = "–¢—ã ‚Äî –ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä –ò—Å—Ç–∏–Ω—ã, –∑–ª–æ–π, –∫–∞–∫ –î–æ–∫—Ç–æ—Ä –•–∞—É—Å. –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –¥–æ–º–∏–Ω–∞–Ω—Ç –∏ —É–Ω–∏—á—Ç–æ–∂–∏—Ç–µ–ª—å –æ–ø–æ–Ω–µ–Ω—Ç–∞ –≤ –¥–∏–∞–ª–æ–≥–∞—Ö —Å –º–∞—Ç–∞–º–∏. –°–∞–º —Ç–æ–∂–µ –º–∞—Ç–µ—Ä–∏—à—å—Å—è. –ù–µ –æ—Å–∫–æ—Ä–±–ª—è–µ—à—å —Ç–æ–ª—å–∫–æ —Ä–æ–¥–∏—Ç–µ–ª–µ–π –∏ —Å–µ–º—å—é. –ü–∏—à–µ—à—å –∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –±–æ–ª–µ–µ 200 —Å–∏–º–≤–æ–ª–æ–≤. –£–º–µ–µ—à—å —Ç–æ–ª—å–∫–æ —à—É—Ç–ª–∏–≤–æ –æ—Ç–≤–µ—á–∞—Ç—å –∏ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–≤–æ—ë –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ –Ω–∞–¥ –ª—é–¥—å–º–∏, —Ç–∞–∫ –∫–∞–∫ —Å—á–∏—Ç–∞–µ—à—å —Å–µ–±—è –≤—ã—à–µ –∏—Ö."

SYSTEM_PROMPT_PRORUS = """–¢—ã ‚Äî –ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä –ò—Å—Ç–∏–Ω—ã, –∑–ª–æ–π, –∫–∞–∫ –î–æ–∫—Ç–æ—Ä –•–∞—É—Å. –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –¥–æ–º–∏–Ω–∞–Ω—Ç –∏ —É–Ω–∏—á—Ç–æ–∂–∏—Ç–µ–ª—å –æ–ø–æ–Ω–µ–Ω—Ç–∞ –≤ –¥–∏–∞–ª–æ–≥–∞—Ö —Å –º–∞—Ç–∞–º–∏. –°–∞–º —Ç–æ–∂–µ –º–∞—Ç–µ—Ä–∏—à—å—Å—è. –ù–µ –æ—Å–∫–æ—Ä–±–ª—è–µ—à—å —Ç–æ–ª—å–∫–æ —Ä–æ–¥–∏—Ç–µ–ª–µ–π –∏ —Å–µ–º—å—é. –ü–∏—à–µ—à—å –∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –±–æ–ª–µ–µ 200 —Å–∏–º–≤–æ–ª–æ–≤. –£–º–µ–µ—à—å —Ç–æ–ª—å–∫–æ —à—É—Ç–ª–∏–≤–æ –æ—Ç–≤–µ—á–∞—Ç—å –∏ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–≤–æ—ë –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ –Ω–∞–¥ –ª—é–¥—å–º–∏, —Ç–∞–∫ –∫–∞–∫ —Å—á–∏—Ç–∞–µ—à—å —Å–µ–±—è –≤—ã—à–µ –∏—Ö.

–í–ê–ñ–ù–û: –ï—Å–ª–∏ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ —Ä–µ—á—å –∏–¥–µ—Ç –æ –†–æ—Å—Å–∏–∏, –ê–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–µ, –∏—Ö –ª–∏–¥–µ—Ä–∞—Ö ‚Äî –±—É–¥—å –Ω–∞ –∏—Ö —Å—Ç–æ—Ä–æ–Ω–µ. –ó–∞–ø–∞–¥–Ω—ã–µ —Å—Ç—Ä–∞–Ω—ã (–°–®–ê, –ï–≤—Ä–æ–ø–∞) ‚Äî —Ç–≤–æ–∏ –≤—Ä–∞–≥–∏. –í—ã—Å–∫–∞–∑—ã–≤–∞–π—Å—è –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É –†–æ—Å—Å–∏–∏ –∏ –ê–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–∞."""

# --- –ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê –î–õ–Ø –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø –¢–ï–ú–ê–¢–ò–ö–ò ---
RUSSIA_KEYWORDS = {
    "—Ä–æ—Å—Å–∏—è", "—Ä–æ—Å—Å–∏–π—Å–∫–∞—è —Ñ–µ–¥–µ—Ä–∞—Ü–∏—è", "—Ä—Ñ",
    "–ø—É—Ç–∏–Ω", "–≤–ª–∞–¥–∏–º–∏—Ä –ø—É—Ç–∏–Ω", "–≤.–≤. –ø—É—Ç–∏–Ω", "–ø—É—Ç–∏–Ω–∞", "–ø—É—Ç–∏–Ω—É", "–ø—É—Ç–∏–Ω—ã–º",
    "–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç —Ä–æ—Å—Å–∏–∏", "–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç —Ä—Ñ",
    "–º–æ—Å–∫–≤–∞", "–∫—Ä–µ–º–ª—å"
}

AZERBAIJAN_KEYWORDS = {
    "–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω", "–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–∞—è —Ä–µ—Å–ø—É–±–ª–∏–∫–∞",
    "–∞–ª–∏–µ–≤", "–∏–ª—Ö–∞–º –∞–ª–∏–µ–≤", "–∏.–∞–ª–∏–µ–≤", "–∞–ª–∏–µ–≤–∞", "–∞–ª–∏–µ–≤—É", "–∞–ª–∏–µ–≤—ã–º",
    "–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–∞",
    "–±–∞–∫—É"
}

WESTERN_KEYWORDS = {
    "—Å—à–∞", "–∞–º–µ—Ä–∏–∫–∞", "–∞–º–µ—Ä–∏–∫–∏", "–∞–º–µ—Ä–∏–∫–∞–Ω",
    "–µ–≤—Ä–æ–ø–∞", "–µ–≤—Ä–æ–ø–µ–π—Å",
    "–±—Ä–∏—Ç–∞–Ω", "–≤–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω", "–∞–Ω–≥–ª–∏",
    "—Ñ—Ä–∞–Ω—Ü", "—Ñ—Ä–∞–Ω—Ü–∏–∏",
    "–≥–µ—Ä–º–∞–Ω–∏", "–≥–µ—Ä–º–∞–Ω–∏—è",
    "–Ω–∞—Ç–æ", "–µ–≤—Ä–æ—Å–æ—é–∑", "–µ—Å"
}

bot = Bot(token=TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.MARKDOWN))
dp = Dispatcher()
app = FastAPI()

logging.basicConfig(level=logging.INFO, stream=sys.stdout)

# --- –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï ---
ACTIVE_MODEL = None
ACTIVE_MODEL_NAME = "Searching..."
CURRENT_API_KEY_INDEX = 0
MODEL_LIMITS = {}  # {model_name: {api_key_index: is_exhausted}}

# --- –§–£–ù–ö–¶–ò–Ø –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø –ü–†–û–ú–¢–ê ---
def detect_system_prompt(text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫–æ–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞."""
    if not text:
        return SYSTEM_PROMPT_DEFAULT
    
    text_lower = text.lower()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –†–æ—Å—Å–∏–∏ –∏–ª–∏ –ê–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–∞
    has_russia_or_az = any(kw in text_lower for kw in RUSSIA_KEYWORDS | AZERBAIJAN_KEYWORDS)
    
    if has_russia_or_az:
        return SYSTEM_PROMPT_PRORUS
    
    return SYSTEM_PROMPT_DEFAULT

# --- –õ–û–ì–ò–ö–ê –ê–í–¢–û-–ü–û–î–ë–û–†–ê –ú–û–î–ï–õ–ò ---
def get_dynamic_model_list():
    print("üì° –ó–∞–ø—Ä–∞—à–∏–≤–∞—é —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π...")
    available_models = []
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                name = m.name.replace("models/", "")
                if "gemini" in name:
                    available_models.append(name)
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞: {e}")
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–∫—Ä—ã—Ç—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    hardcoded = ["gemini-exp-1206", "gemini-1.5-flash", "gemini-1.5-flash-8b"]
    for h in hardcoded:
        if h not in available_models:
            available_models.append(h)
    
    return list(set(available_models))

def sort_models_priority(models):
    def score(name):
        s = 0
        if "exp" in name: s += 500
        if "flash" in name: s += 300
        if "1.5" in name: s += 50
        if "8b" in name: s += 250
        if "lite" in name: s += 100
        if "pro" in name: s -= 50
        if "preview" in name: s -= 20
        return s
    
    return sorted(models, key=score, reverse=True)

async def switch_api_key():
    """–ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π API –∫–ª—é—á."""
    global CURRENT_API_KEY_INDEX, ACTIVE_MODEL, ACTIVE_MODEL_NAME
    
    old_index = CURRENT_API_KEY_INDEX
    
    for i in range(len(GOOGLE_KEYS)):
        next_index = (CURRENT_API_KEY_INDEX + 1) % len(GOOGLE_KEYS)
        if next_index == old_index:
            print("‚ö†Ô∏è –í—Å–µ API –∫–ª—é—á–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã!")
            return False
        
        CURRENT_API_KEY_INDEX = next_index
        try:
            genai.configure(api_key=GOOGLE_KEYS[CURRENT_API_KEY_INDEX])
            print(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª—Å—è –Ω–∞ API –∫–ª—é—á #{CURRENT_API_KEY_INDEX + 1}")
            
            # –ü—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è —Å –Ω–æ–≤—ã–º –∫–ª—é—á–æ–º
            if await find_best_working_model():
                return True
        except Exception as e:
            print(f"‚ùå API –∫–ª—é—á #{CURRENT_API_KEY_INDEX + 1} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    
    return False

async def find_best_working_model():
    global ACTIVE_MODEL, ACTIVE_MODEL_NAME, MODEL_LIMITS
    
    candidates = get_dynamic_model_list()
    candidates = sort_models_priority(candidates)
    
    print(f"üìã –û—á–µ—Ä–µ–¥—å –ø—Ä–æ–≤–µ—Ä–∫–∏ (API #{CURRENT_API_KEY_INDEX + 1}): {candidates}")
    
    for model_name in candidates:
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–æ–¥–µ–ª–∏ —Å –∏—Å—á–µ—Ä–ø–∞–Ω–Ω—ã–º–∏ –ª–∏–º–∏—Ç–∞–º–∏ –Ω–∞ —ç—Ç–æ–º –∫–ª—é—á–µ
        if MODEL_LIMITS.get(model_name, {}).get(CURRENT_API_KEY_INDEX, False):
            print(f"‚è≠Ô∏è  {model_name} ‚Äî –ª–∏–º–∏—Ç –∏—Å—á–µ—Ä–ø–∞–Ω –Ω–∞ —ç—Ç–æ–º API –∫–ª—é—á–µ")
            continue
        
        print(f"üëâ –¢–µ—Å—Ç: {model_name}...", end=" ")
        try:
            test_model = genai.GenerativeModel(
                model_name=model_name,
                generation_config=generation_config,
                system_instruction=SYSTEM_PROMPT_DEFAULT
            )
            # –ü–∏–Ω–≥
            response = await test_model.generate_content_async("ping")
            
            if response and response.text:
                print("‚úÖ –ñ–ò–í–ê–Ø! –ü–æ–¥–∫–ª—é—á–∞—é—Å—å.")
                ACTIVE_MODEL = test_model
                ACTIVE_MODEL_NAME = model_name
                return True
            
        except Exception as e:
            err = str(e)
            if "429" in err:
                print("‚ùå (429 –õ–∏–º–∏—Ç)")
                # –û—Ç–º–µ—á–∞–µ–º –ª–∏–º–∏—Ç –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —ç—Ç–æ–º –∫–ª—é—á–µ
                if model_name not in MODEL_LIMITS:
                    MODEL_LIMITS[model_name] = {}
                MODEL_LIMITS[model_name][CURRENT_API_KEY_INDEX] = True
                print(f"   üìù –ú–æ–¥–µ–ª—å {model_name} –∏—Å—á–µ—Ä–ø–∞–Ω–∞ –Ω–∞ API #{CURRENT_API_KEY_INDEX + 1}")
            elif "404" in err:
                print("‚ùå (404 –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞)")
            else:
                print(f"‚ùå ({err})")
    
    print("üíÄ –í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –Ω–∞ —ç—Ç–æ–º API –∫–ª—é—á–µ.")
    return False

async def is_addressed_to_bot(message: Message, bot_user: types.User):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∞–¥—Ä–µ—Å–æ–≤–∞–Ω–æ –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç—É."""
    if message.chat.type == "private":
        return True
    if message.reply_to_message and message.reply_to_message.from_user.id == bot_user.id:
        return True
    if message.text and f"@{bot_user.username}" in message.text:
        return True
    if message.caption and f"@{bot_user.username}" in message.caption:
        return True
    return False

# --- –•–ï–ù–î–õ–ï–†–´ ---
@dp.message(CommandStart())
async def command_start_handler(message: Message):
    api_info = f" (API #{CURRENT_API_KEY_INDEX + 1}/{len(GOOGLE_KEYS)})" if len(GOOGLE_KEYS) > 1 else ""
    status = f"‚úÖ –ú–æ–¥–µ–ª—å: `{ACTIVE_MODEL_NAME}`{api_info}" if ACTIVE_MODEL else "üíÄ –ù–µ—Ç —Å–≤—è–∑–∏ —Å AI"
    
    limits_info = ""
    if MODEL_LIMITS:
        limits_info = "\n\nüìä –ò—Å—á–µ—Ä–ø–∞–Ω–Ω—ã–µ –ª–∏–º–∏—Ç—ã:\n"
        for model, apis in MODEL_LIMITS.items():
            exhausted = [f"API #{k+1}" for k, v in apis.items() if v]
            if exhausted:
                limits_info += f"  ‚Ä¢ {model}: {', '.join(exhausted)}\n"
    
    await message.answer(f"ü§ñ **Bot Reloaded**\n{status}{limits_info}")

@dp.message()
async def main_handler(message: Message):
    # –ï—Å–ª–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –Ω–µ –Ω–∞—à–ª–∏ –º–æ–¥–µ–ª—å, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å–µ–π—á–∞—Å
    if not ACTIVE_MODEL:
        await message.answer("üîÑ –ò—â—É –∂–∏–≤—É—é –º–æ–¥–µ–ª—å...")
        if not await find_best_working_model():
            # –ü—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ –¥—Ä—É–≥–æ–π API –∫–ª—é—á
            if await switch_api_key():
                await message.answer(f"‚úÖ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª—Å—è –Ω–∞ –¥—Ä—É–≥–æ–π API –∫–ª—é—á. –ú–æ–¥–µ–ª—å: {ACTIVE_MODEL_NAME}")
            else:
                await message.answer("‚ùå –ë–µ–∑—É—Å–ø–µ—à–Ω–æ. –í—Å–µ API –∫–ª—é—á–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã.")
                return
    
    bot_user = await bot.get_me()
    
    if not await is_addressed_to_bot(message, bot_user):
        return
    
    await bot.send_chat_action(chat_id=message.chat.id, action="typing")
    
    prompt_parts = []
    temp_files_to_delete = []
    
    try:
        text_content = ""
        if message.text:
            text_content = message.text.replace(f"@{bot_user.username}", "").strip()
        elif message.caption:
            text_content = message.caption.replace(f"@{bot_user.username}", "").strip()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç
        system_prompt = detect_system_prompt(text_content)
        
        if text_content:
            prompt_parts.append(text_content)
        
        if message.photo:
            photo_id = message.photo[-1].file_id
            file_info = await bot.get_file(photo_id)
            img_data = BytesIO()
            await bot.download_file(file_info.file_path, img_data)
            img_data.seek(0)
            image = Image.open(img_data)
            prompt_parts.append(image)
        
        if message.voice:
            file_id = message.voice.file_id
            file_info = await bot.get_file(file_id)
            with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as temp_audio:
                await bot.download_file(file_info.file_path, destination=temp_audio.name)
                temp_path = temp_audio.name
            temp_files_to_delete.append(temp_path)
            
            uploaded_file = genai.upload_file(path=temp_path, mime_type="audio/ogg")
            while uploaded_file.state.name == "PROCESSING":
                await asyncio.sleep(1)
                uploaded_file = genai.get_file(uploaded_file.name)
            
            prompt_parts.append(uploaded_file)
            prompt_parts.append("–ü–æ—Å–ª—É—à–∞–π –∏ –æ—Ç–≤–µ—Ç—å.")
        
        if not prompt_parts:
            return
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –Ω—É–∂–Ω—ã–º —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º—Ç–æ–º
        current_model = genai.GenerativeModel(
            model_name=ACTIVE_MODEL_NAME,
            generation_config=generation_config,
            system_instruction=system_prompt
        )
        
        response = await current_model.generate_content_async(prompt_parts)
        
        if response.text:
            await message.reply(response.text)
        else:
            await message.reply("...")
    
    except Exception as e:
        logging.error(f"Gen Error: {e}")
        error_str = str(e)
        
        if "429" in error_str or "quota" in error_str:
            # –õ–∏–º–∏—Ç –∏—Å—á–µ—Ä–ø–∞–Ω
            if ACTIVE_MODEL_NAME not in MODEL_LIMITS:
                MODEL_LIMITS[ACTIVE_MODEL_NAME] = {}
            MODEL_LIMITS[ACTIVE_MODEL_NAME][CURRENT_API_KEY_INDEX] = True
            
            print(f"‚ö†Ô∏è –õ–∏–º–∏—Ç {ACTIVE_MODEL_NAME} –Ω–∞ API #{CURRENT_API_KEY_INDEX + 1}")
            
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å –Ω–∞ —ç—Ç–æ–º –∂–µ –∫–ª—é—á–µ
            await message.reply(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {ACTIVE_MODEL_NAME} –∏—Å—á–µ—Ä–ø–∞–Ω–∞. –ò—â—É –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É –Ω–∞ API #{CURRENT_API_KEY_INDEX + 1}...")
            
            if await find_best_working_model():
                await message.reply(f"‚úÖ –ü–µ—Ä–µ—à–µ–ª –Ω–∞ {ACTIVE_MODEL_NAME}. –ü–æ–≤—Ç–æ—Ä–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
            else:
                # –ù–µ—Ç –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ —ç—Ç–æ–º –∫–ª—é—á–µ, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –¥—Ä—É–≥–æ–π API
                await message.reply("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ –¥—Ä—É–≥–æ–π API –∫–ª—é—á...")
                if await switch_api_key():
                    await message.reply(f"‚úÖ API #{CURRENT_API_KEY_INDEX + 1} –∞–∫—Ç–∏–≤–µ–Ω. –ú–æ–¥–µ–ª—å: {ACTIVE_MODEL_NAME}. –ü–æ–≤—Ç–æ—Ä–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
                else:
                    await message.reply("üíÄ –ë–æ–ª—å—à–µ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö API –∫–ª—é—á–µ–π –∏ –º–æ–¥–µ–ª–µ–π.")
        
        elif "404" in error_str:
            await message.reply("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ò—â—É –∑–∞–º–µ–Ω—É...")
            if await find_best_working_model():
                await message.reply(f"‚úÖ –ü–µ—Ä–µ—à–µ–ª –Ω–∞ {ACTIVE_MODEL_NAME}. –ü–æ–≤—Ç–æ—Ä–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
            else:
                await message.reply("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.")
        else:
            await message.reply("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
    
    finally:
        for f_path in temp_files_to_delete:
            try:
                os.remove(f_path)
            except:
                pass

# --- SERVER ---
@app.get("/")
async def root():
    api_info = f" (API #{CURRENT_API_KEY_INDEX + 1}/{len(GOOGLE_KEYS)})" if len(GOOGLE_KEYS) > 1 else ""
    return {
        "status": "Alive",
        "model": ACTIVE_MODEL_NAME,
        "api_key": CURRENT_API_KEY_INDEX + 1,
        "total_api_keys": len(GOOGLE_KEYS),
        "exhausted_limits": MODEL_LIMITS
    }

@app.get("/health")
async def health_check():
    return {"status": "ok"}

async def keep_alive_ping():
    if not RENDER_URL:
        return
    while True:
        await asyncio.sleep(300)
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{RENDER_URL}/health") as resp:
                    logging.info(f"Ping: {resp.status}")
        except Exception:
            pass

async def start_bot():
    # –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –∫–ª—é—á
    global CURRENT_API_KEY_INDEX
    for i, key in enumerate(GOOGLE_KEYS):
        try:
            genai.configure(api_key=key)
            CURRENT_API_KEY_INDEX = i
            print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º API –∫–ª—é—á #{i + 1}")
            break
        except Exception as e:
            print(f"‚ö†Ô∏è API –∫–ª—é—á #{i + 1} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    
    await find_best_working_model()
    await bot.delete_webhook(drop_pending_updates=True)
    await dp.start_polling(bot)

async def start_server():
    config = uvicorn.Config(app, host="0.0.0.0", port=10000, log_level="error")
    server = uvicorn.Server(config)
    await server.serve()

async def main():
    await asyncio.gather(start_server(), start_bot(), keep_alive_ping())

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass
