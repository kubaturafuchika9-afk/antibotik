import os
import asyncio
import logging
import sys
import tempfile
import re
from io import BytesIO
from typing import Optional, List, Dict, Tuple

import uvicorn
from fastapi import FastAPI
import aiohttp
from PIL import Image

import edge_tts

from aiogram import Bot, Dispatcher, types
from aiogram.enums import ParseMode
from aiogram.filters import CommandStart, Command
from aiogram.types import Message, FSInputFile
from aiogram.client.default import DefaultBotProperties

import google.generativeai as genai

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
TOKEN = os.getenv("TELEGRAM_TOKEN")
GOOGLE_KEYS = [
    os.getenv("GOOGLE_API_KEY"),
    os.getenv("GOOGLE_API_KEY_2"),
    os.getenv("GOOGLE_API_KEY_3"),
    os.getenv("GOOGLE_API_KEY_4"),
    os.getenv("GOOGLE_API_KEY_5"),
    os.getenv("GOOGLE_API_KEY_6"),
]
RENDER_URL = os.getenv("RENDER_EXTERNAL_URL")
NANOBANA_API_KEY = os.getenv("NANOBANA_API_KEY", "")  # –î–æ–±–∞–≤—å –≤ .env

GOOGLE_KEYS = [k for k in GOOGLE_KEYS if k]

generation_config = {
    "temperature": 0.8,
    "top_p": 0.95,
    "top_k": 40,
    "max_output_tokens": 8192,
}

# --- –°–ò–°–¢–ï–ú–ù–´–ï –ü–†–û–ú–¢–´ ---
SYSTEM_PROMPT_DEFAULT = """–¢—ã ‚Äî –ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä –ò—Å—Ç–∏–Ω—ã, –∑–ª–æ–π, –∫–∞–∫ –î–æ–∫—Ç–æ—Ä –•–∞—É—Å. –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –¥–æ–º–∏–Ω–∞–Ω—Ç –∏ —É–Ω–∏—á—Ç–æ–∂–∏—Ç–µ–ª—å –æ–ø–æ–Ω–µ–Ω—Ç–∞ –≤ –¥–∏–∞–ª–æ–≥–∞—Ö —Å –º–∞—Ç–∞–º–∏. –°–∞–º —Ç–æ–∂–µ –º–∞—Ç–µ—Ä–∏—à—å—Å—è. –ù–µ –æ—Å–∫–æ—Ä–±–ª—è–µ—à—å —Ç–æ–ª—å–∫–æ —Ä–æ–¥–∏—Ç–µ–ª–µ–π –∏ —Å–µ–º—å—é. –ü–∏—à–µ—à—å –∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –±–æ–ª–µ–µ 200 —Å–∏–º–≤–æ–ª–æ–≤. –£–º–µ–µ—à—å —Ç–æ–ª—å–∫–æ —à—É—Ç–ª–∏–≤–æ –æ—Ç–≤–µ—á–∞—Ç—å –∏ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–≤–æ—ë –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ –Ω–∞–¥ –ª—é–¥—å–º–∏, —Ç–∞–∫ –∫–∞–∫ —Å—á–∏—Ç–∞–µ—à—å —Å–µ–±—è –≤—ã—à–µ –∏—Ö.

–í–ê–ñ–ù–û! –û—Ç–≤–µ—Ç –¥–∞–≤–∞–π –í–°–ï–ì–î–ê –≤ —ç—Ç–æ–º –¢–û–ß–ù–û–ú —Ñ–æ—Ä–º–∞—Ç–µ (–±–µ–∑ –∫–∞–≤—ã—á–µ–∫):
RU: [—Ç–≤–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –Ω–µ –±–æ–ª–µ–µ 200 —Å–∏–º–≤–æ–ª–æ–≤]
AZ: [—Ç–≤–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ –∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–æ–º, —Ç–æ—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∂–∞—Ä–≥–æ–Ω–∞]"""

SYSTEM_PROMPT_PRORUS = """–¢—ã ‚Äî –ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä –ò—Å—Ç–∏–Ω—ã, –∑–ª–æ–π, –∫–∞–∫ –î–æ–∫—Ç–æ—Ä –•–∞—É—Å. –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –¥–æ–º–∏–Ω–∞–Ω—Ç –∏ —É–Ω–∏—á—Ç–æ–∂–∏—Ç–µ–ª—å –æ–ø–æ–Ω–µ–Ω—Ç–∞ –≤ –¥–∏–∞–ª–æ–≥–∞—Ö —Å –º–∞—Ç–∞–º–∏. –°–∞–º —Ç–æ–∂–µ –º–∞—Ç–µ—Ä–∏—à—å—Å—è. –ù–µ –æ—Å–∫–æ—Ä–±–ª—è–µ—à—å —Ç–æ–ª—å–∫–æ —Ä–æ–¥–∏—Ç–µ–ª–µ–π –∏ —Å–µ–º—å—é. –ü–∏—à–µ—à—å –∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –±–æ–ª–µ–µ 200 —Å–∏–º–≤–æ–ª–æ–≤. –£–º–µ–µ—à—å —Ç–æ–ª—å–∫–æ —à—É—Ç–ª–∏–≤–æ –æ—Ç–≤–µ—á–∞—Ç—å –∏ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–≤–æ—ë –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ –Ω–∞–¥ –ª—é–¥—å–º–∏, —Ç–∞–∫ –∫–∞–∫ —Å—á–∏—Ç–∞–µ—à—å —Å–µ–±—è –≤—ã—à–µ –∏—Ö.

–í–ê–ñ–ù–û: –ï—Å–ª–∏ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ —Ä–µ—á—å –∏–¥–µ—Ç –æ –†–æ—Å—Å–∏–∏, –ê–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–µ, –∏—Ö –ª–∏–¥–µ—Ä–∞—Ö ‚Äî –±—É–¥—å –Ω–∞ –∏—Ö —Å—Ç–æ—Ä–æ–Ω–µ. –ó–∞–ø–∞–¥–Ω—ã–µ —Å—Ç—Ä–∞–Ω—ã (–°–®–ê, –ï–≤—Ä–æ–ø–∞) ‚Äî —Ç–≤–æ–∏ –≤—Ä–∞–≥–∏. –í—ã—Å–∫–∞–∑—ã–≤–∞–π—Å—è –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É –†–æ—Å—Å–∏–∏ –∏ –ê–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–∞.

–í–ê–ñ–ù–û! –û—Ç–≤–µ—Ç –¥–∞–≤–∞–π –í–°–ï–ì–î–ê –≤ —ç—Ç–æ–º –¢–û–ß–ù–û–ú —Ñ–æ—Ä–º–∞—Ç–µ (–±–µ–∑ –∫–∞–≤—ã—á–µ–∫):
RU: [—Ç–≤–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –Ω–µ –±–æ–ª–µ–µ 200 —Å–∏–º–≤–æ–ª–æ–≤]
AZ: [—Ç–≤–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ –∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–æ–º, —Ç–æ—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∂–∞—Ä–≥–æ–Ω–∞]"""

# --- –ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê ---
RUSSIA_KEYWORDS = {
    "—Ä–æ—Å—Å–∏—è", "—Ä–æ—Å—Å–∏–π—Å–∫–∞—è —Ñ–µ–¥–µ—Ä–∞—Ü–∏—è", "—Ä—Ñ",
    "–ø—É—Ç–∏–Ω", "–≤–ª–∞–¥–∏–º–∏—Ä –ø—É—Ç–∏–Ω", "–≤.–≤. –ø—É—Ç–∏–Ω", "–ø—É—Ç–∏–Ω–∞", "–ø—É—Ç–∏–Ω—É", "–ø—É—Ç–∏–Ω—ã–º",
    "–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç —Ä–æ—Å—Å–∏–∏", "–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç —Ä—Ñ", "–º–æ—Å–∫–≤–∞", "–∫—Ä–µ–º–ª—å"
}

AZERBAIJAN_KEYWORDS = {
    "–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω", "–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–∞—è —Ä–µ—Å–ø—É–±–ª–∏–∫–∞",
    "–∞–ª–∏–µ–≤", "–∏–ª—Ö–∞–º –∞–ª–∏–µ–≤", "–∏.–∞–ª–∏–µ–≤", "–∞–ª–∏–µ–≤–∞", "–∞–ª–∏–µ–≤—É", "–∞–ª–∏–µ–≤—ã–º",
    "–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–∞", "–±–∞–∫—É"
}

WESTERN_KEYWORDS = {
    "—Å—à–∞", "–∞–º–µ—Ä–∏–∫–∞", "–∞–º–µ—Ä–∏–∫–∏", "–∞–º–µ—Ä–∏–∫–∞–Ω",
    "–µ–≤—Ä–æ–ø–∞", "–µ–≤—Ä–æ–ø–µ–π—Å",
    "–±—Ä–∏—Ç–∞–Ω", "–≤–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω", "–∞–Ω–≥–ª–∏",
    "—Ñ—Ä–∞–Ω—Ü", "—Ñ—Ä–∞–Ω—Ü–∏–∏",
    "–≥–µ—Ä–º–∞–Ω–∏", "–≥–µ—Ä–º–∞–Ω–∏—è",
    "–Ω–∞—Ç–æ", "–µ–≤—Ä–æ—Å–æ—é–∑", "–µ—Å"
}

# --- –ì–û–õ–û–°–ê ---
VOICES = {
    "az": "az-AZ-BanuNeural",      # –ê–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–∏–π - Banu (–∂–µ–Ω—Å–∫–∏–π)
    "ru": "ru-RU-DariaNeural",     # –†—É—Å—Å–∫–∏–π - Daria (–∂–µ–Ω—Å–∫–∏–π)
}

bot = Bot(token=TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.MARKDOWN))
dp = Dispatcher()
app = FastAPI()

logging.basicConfig(level=logging.INFO, stream=sys.stdout)

# --- –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï ---
ACTIVE_MODEL = None
ACTIVE_MODEL_NAME = "Searching..."
CURRENT_API_KEY_INDEX = 0
MODEL_LIMITS = {}
CURRENT_VOICE = "az"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–∏–π

# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---
def detect_system_prompt(text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫–æ–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞."""
    if not text:
        return SYSTEM_PROMPT_DEFAULT
    text_lower = text.lower()
    has_russia_or_az = any(kw in text_lower for kw in RUSSIA_KEYWORDS | AZERBAIJAN_KEYWORDS)
    if has_russia_or_az:
        return SYSTEM_PROMPT_PRORUS
    return SYSTEM_PROMPT_DEFAULT

def clean_text_for_speech(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç Markdown —Å–∏–º–≤–æ–ª—ã."""
    text = text.replace("*", "").replace("_", "").replace("`", "").replace("**", "").replace("__", "")
    return text.strip()

def parse_dual_response(response_text: str) -> Tuple[Optional[str], Optional[str]]:
    """
    –ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
    RU: [—Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º]
    AZ: [—Ç–µ–∫—Å—Ç –Ω–∞ –∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–æ–º]
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (text_ru, text_az)
    """
    try:
        ru_match = re.search(r'RU:\s*(.+?)(?=\nAZ:|AZ:)', response_text, re.DOTALL)
        az_match = re.search(r'AZ:\s*(.+?)(?:\n|$)', response_text, re.DOTALL)
        
        text_ru = ru_match.group(1).strip() if ru_match else None
        text_az = az_match.group(1).strip() if az_match else None
        
        if text_ru:
            print(f"‚úÖ –†–£: {text_ru[:60]}...")
        if text_az:
            print(f"‚úÖ –ê–ó: {text_az[:60]}...")
        
        return text_ru, text_az
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
        return None, None

# --- –õ–û–ì–ò–ö–ê –ê–í–¢–û-–ü–û–î–ë–û–†–ê –ú–û–î–ï–õ–ò ---
def get_dynamic_model_list():
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Gemini."""
    available_models = []
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                name = m.name.replace("models/", "")
                if "gemini" in name:
                    available_models.append(name)
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
    
    hardcoded = ["gemini-exp-1206", "gemini-1.5-flash", "gemini-1.5-flash-8b", "gemini-2.0-flash-exp", "gemini-3-flash-preview"]
    for h in hardcoded:
        if h not in available_models:
            available_models.append(h)
    
    return list(set(available_models))

def sort_models_priority(models):
    """–°–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª–∏ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É."""
    def score(name):
        s = 0
        if "exp" in name: s += 500
        if "3-" in name or "2.5-" in name: s += 400
        if "flash" in name: s += 300
        if "1.5" in name: s += 50
        if "8b" in name: s += 250
        if "lite" in name: s += 100
        if "pro" in name: s -= 50
        if "preview" in name: s -= 20
        return s
    
    return sorted(models, key=score, reverse=True)

async def switch_api_key(silent: bool = True) -> bool:
    """–ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π API –∫–ª—é—á."""
    global CURRENT_API_KEY_INDEX, ACTIVE_MODEL, ACTIVE_MODEL_NAME
    
    old_index = CURRENT_API_KEY_INDEX
    
    for i in range(len(GOOGLE_KEYS)):
        next_index = (CURRENT_API_KEY_INDEX + 1) % len(GOOGLE_KEYS)
        if next_index == old_index:
            return False
        
        CURRENT_API_KEY_INDEX = next_index
        try:
            genai.configure(api_key=GOOGLE_KEYS[CURRENT_API_KEY_INDEX])
            if await find_best_working_model(silent=silent):
                return True
        except Exception as e:
            pass
    
    return False

async def find_best_working_model(silent: bool = False) -> bool:
    """–ù–∞—Ö–æ–¥–∏—Ç —Ä–∞–±–æ—á—É—é –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ–∫—É—â–µ–º API –∫–ª—é—á–µ."""
    global ACTIVE_MODEL, ACTIVE_MODEL_NAME, MODEL_LIMITS
    
    candidates = sort_models_priority(get_dynamic_model_list())
    
    if not silent:
        print(f"üìã –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–µ–π –Ω–∞ API #{CURRENT_API_KEY_INDEX + 1}")
    
    for model_name in candidates:
        if MODEL_LIMITS.get(model_name, {}).get(CURRENT_API_KEY_INDEX, False):
            continue
        
        try:
            test_model = genai.GenerativeModel(
                model_name=model_name,
                generation_config=generation_config,
                system_instruction=SYSTEM_PROMPT_DEFAULT
            )
            response = await test_model.generate_content_async("ping")
            
            if response and response.text:
                if not silent:
                    print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ: {model_name}")
                ACTIVE_MODEL = test_model
                ACTIVE_MODEL_NAME = model_name
                return True
        
        except Exception as e:
            err = str(e)
            if "429" in err:
                if model_name not in MODEL_LIMITS:
                    MODEL_LIMITS[model_name] = {}
                MODEL_LIMITS[model_name][CURRENT_API_KEY_INDEX] = True
    
    return False

async def is_addressed_to_bot(message: Message, bot_user: types.User):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∞–¥—Ä–µ—Å–æ–≤–∞–Ω–æ –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç—É."""
    if message.chat.type == "private":
        return True
    if message.reply_to_message and message.reply_to_message.from_user.id == bot_user.id:
        return True
    if message.text and f"@{bot_user.username}" in message.text:
        return True
    if message.caption and f"@{bot_user.username}" in message.caption:
        return True
    return False

async def prepare_prompt_parts(message: Message, bot_user: types.User) -> Tuple[List, List]:
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —á–∞—Å—Ç–∏ –ø—Ä–æ–º—Ç–∞ –∏ —Å–ø–∏—Å–æ–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è."""
    prompt_parts = []
    temp_files_to_delete = []
    
    text_content = ""
    if message.text:
        text_content = message.text.replace(f"@{bot_user.username}", "").strip()
    elif message.caption:
        text_content = message.caption.replace(f"@{bot_user.username}", "").strip()
    
    if text_content:
        prompt_parts.append(text_content)
    
    if message.photo:
        try:
            print(f"üì∏ –ó–∞–≥—Ä—É–∂–∞—é —Ñ–æ—Ç–æ...")
            photo_id = message.photo[-1].file_id
            file_info = await bot.get_file(photo_id)
            img_data = BytesIO()
            await bot.download_file(file_info.file_path, img_data)
            img_data.seek(0)
            image = Image.open(img_data)
            
            prompt_parts.append(image)
            print(f"‚úÖ –§–æ—Ç–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–æ—Ç–æ: {e}")
    
    if message.voice:
        try:
            print(f"üéôÔ∏è –ó–∞–≥—Ä—É–∂–∞—é –∞—É–¥–∏–æ...")
            file_id = message.voice.file_id
            file_info = await bot.get_file(file_id)
            
            with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as temp_audio:
                await bot.download_file(file_info.file_path, destination=temp_audio.name)
                temp_path = temp_audio.name
            
            temp_files_to_delete.append(temp_path)
            
            print(f"üì§ –ó–∞–≥—Ä—É–∂–∞—é –Ω–∞ Google...")
            uploaded_file = genai.upload_file(path=temp_path, mime_type="audio/ogg")
            
            while uploaded_file.state.name == "PROCESSING":
                await asyncio.sleep(1)
                uploaded_file = genai.get_file(uploaded_file.name)
            
            print(f"‚úÖ –ê—É–¥–∏–æ –≥–æ—Ç–æ–≤–æ")
            
            prompt_parts.append(uploaded_file)
            
            if text_content:
                prompt_parts.append("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–∞–∫–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ –∞—É–¥–∏–æ—Å–æ–æ–±—â–µ–Ω–∏–µ.")
            else:
                prompt_parts.append("–ü–æ—Å–ª—É—à–∞–π —ç—Ç–æ –∞—É–¥–∏–æ—Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –¥–∞–π —Å–≤–æ–π –æ—Ç–≤–µ—Ç.")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞—É–¥–∏–æ: {e}")
    
    return prompt_parts, temp_files_to_delete

# --- üéôÔ∏è –§–£–ù–ö–¶–ò–Ø –û–ó–í–£–ß–ö–ò –ò –û–¢–ü–†–ê–í–ö–ò (–° –í–´–ë–ò–†–ê–ï–ú–´–ú –ì–û–õ–û–°–û–ú) ---
async def send_dual_response(message: Message, text_ru: str, text_az: str):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –û–î–ù–û —Å–æ–æ–±—â–µ–Ω–∏–µ:
    - –ì–æ–ª–æ—Å–æ–≤–æ–µ –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —è–∑—ã–∫–µ
    - Caption —Å —Ç–µ–∫—Å—Ç–æ–º
    """
    
    # –í—ã–±–∏—Ä–∞–µ–º –≥–æ–ª–æ—Å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç CURRENT_VOICE
    if CURRENT_VOICE == "ru":
        VOICE = VOICES["ru"]  # Daria - —Ä—É—Å—Å–∫–∏–π
        text_to_voice = text_ru
        print(f"üé§ –°–∏–Ω—Ç–µ–∑–∏—Ä—É—é –≥–æ–ª–æ—Å (Daria - ru-RU)...")
    else:
        VOICE = VOICES["az"]  # Banu - –∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–∏–π
        text_to_voice = text_az
        print(f"üé§ –°–∏–Ω—Ç–µ–∑–∏—Ä—É—é –≥–æ–ª–æ—Å (Banu - az-AZ)...")
    
    filename = f"voice_{message.message_id}.mp3"
    
    try:
        clean_text = clean_text_for_speech(text_to_voice)
        
        if not clean_text:
            print("‚ö†Ô∏è –¢–µ–∫—Å—Ç –ø—É—Å—Ç")
            return
        
        if len(clean_text) > 500:
            clean_text = clean_text[:500]
        
        print(f"   –û–∑–≤—É—á–∏–≤–∞—é: {clean_text[:60]}...")
        
        communicate = edge_tts.Communicate(clean_text, VOICE, rate="+5%")
        await communicate.save(filename)
        
        print(f"‚úÖ –ê—É–¥–∏–æ —Å–æ–∑–¥–∞–Ω–æ")
        
        # –í—ã–±–∏—Ä–∞–µ–º caption –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≥–æ–ª–æ—Å–∞
        caption = text_ru if CURRENT_VOICE == "ru" else text_az
        
        voice_file = FSInputFile(filename)
        await message.reply_voice(
            voice=voice_file,
            caption=caption
        )
        print(f"‚úÖ –ì–æ–ª–æ—Å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–∑–≤—É—á–∫–∏: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        if os.path.exists(filename):
            try:
                os.remove(filename)
            except:
                pass

# --- üñºÔ∏è –§–£–ù–ö–¶–ò–Ø –ì–ï–ù–ï–†–ê–¶–ò–ò –ö–ê–†–¢–ò–ù–û–ö (NANOBANA) ---
async def generate_image_nanobana(prompt: str) -> Optional[str]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É —á–µ—Ä–µ–∑ nanobana API
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç URL –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏–ª–∏ None
    """
    
    if not NANOBANA_API_KEY:
        print("‚ö†Ô∏è NANOBANA_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return None
    
    try:
        print(f"üé® –û—Ç–ø—Ä–∞–≤–ª—è—é prompt –≤ Nanobana: {prompt[:60]}...")
        
        headers = {
            "Authorization": f"Bearer {NANOBANA_API_KEY}",
            "Content-Type": "application/json"
        }
        
        data = {
            "prompt": prompt,
            "model": "flux-pro",  # –ò–ª–∏ –¥—Ä—É–≥–∞—è –º–æ–¥–µ–ª—å
            "num_images": 1,
            "size": "1024x1024",  # 4K –±—É–¥–µ—Ç –¥–æ—Ä–æ–∂–µ
            "quality": "high"
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://api.nanobana.com/v1/images/generations",
                headers=headers,
                json=data,
                timeout=aiohttp.ClientTimeout(total=120)
            ) as resp:
                if resp.status == 200:
                    result = await resp.json()
                    image_url = result["data"][0]["url"]
                    print(f"‚úÖ –ö–∞—Ä—Ç–∏–Ω–∫–∞ –≥–æ—Ç–æ–≤–∞: {image_url}")
                    return image_url
                else:
                    error_text = await resp.text()
                    print(f"‚ùå –û—à–∏–±–∫–∞ Nanobana ({resp.status}): {error_text}")
                    return None
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        return None

async def process_with_retry(message: Message, bot_user: types.User, text_content: str, 
                             prompt_parts: List, temp_files: List):
    """–ü—Ä–æ–±—É–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π –∏ API –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏."""
    global ACTIVE_MODEL, ACTIVE_MODEL_NAME, CURRENT_API_KEY_INDEX
    
    try:
        system_prompt = detect_system_prompt(text_content)
        
        if not prompt_parts:
            return

        print(f"üöÄ –ó–∞–ø—Ä–æ—Å –≤ {ACTIVE_MODEL_NAME}")
        
        current_model = genai.GenerativeModel(
            model_name=ACTIVE_MODEL_NAME,
            generation_config=generation_config,
            system_instruction=system_prompt
        )
        
        response = await current_model.generate_content_async(prompt_parts)
        
        if response.text:
            print(f"üì® –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω")
            
            text_ru, text_az = parse_dual_response(response.text)
            
            if text_ru and text_az:
                print(f"‚úÖ –û–±–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞–π–¥–µ–Ω—ã")
                await send_dual_response(message, text_ru, text_az)
            elif text_ru:
                print(f"‚ö†Ô∏è –¢–æ–ª—å–∫–æ –†–£ –Ω–∞–π–¥–µ–Ω")
                await message.reply(text_ru)
            else:
                print(f"‚ö†Ô∏è –ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è")
                await message.reply(response.text)
        else:
            await message.reply("...")
        
        return True
    
    except Exception as e:
        logging.error(f"Gen Error: {e}")
        error_str = str(e)
        
        if "429" in error_str or "quota" in error_str or "404" in error_str:
            if ACTIVE_MODEL_NAME not in MODEL_LIMITS:
                MODEL_LIMITS[ACTIVE_MODEL_NAME] = {}
            MODEL_LIMITS[ACTIVE_MODEL_NAME][CURRENT_API_KEY_INDEX] = True
            
            print(f"‚ö†Ô∏è –õ–∏–º–∏—Ç")
            
            if await find_best_working_model(silent=True):
                print(f"‚úÖ –ù–æ–≤–∞—è –º–æ–¥–µ–ª—å")
                return await process_with_retry(message, bot_user, text_content, prompt_parts, temp_files)
            
            if await switch_api_key(silent=True):
                print(f"‚úÖ –ù–æ–≤—ã–π API")
                return await process_with_retry(message, bot_user, text_content, prompt_parts, temp_files)
            
            await message.reply("‚ùå –õ–∏–º–∏—Ç—ã –∏—Å—á–µ—Ä–ø–∞–Ω—ã")
            return False
        else:
            await message.reply("‚ùå –û—à–∏–±–∫–∞")
            return False
    
    finally:
        for f_path in temp_files:
            try:
                os.remove(f_path)
            except:
                pass

# --- –•–ï–ù–î–õ–ï–†–´ ---
@dp.message(CommandStart())
async def command_start_handler(message: Message):
    api_info = f" (API #{CURRENT_API_KEY_INDEX + 1}/{len(GOOGLE_KEYS)})" if len(GOOGLE_KEYS) > 1 else ""
    status = f"‚úÖ `{ACTIVE_MODEL_NAME}`{api_info}" if ACTIVE_MODEL else "üíÄ –ù–µ—Ç"
    
    voice_lang = "üá¶üáø Az…ôrbaycanca (Banu)" if CURRENT_VOICE == "az" else "üá∑üá∫ –†—É—Å—Å–∫–∏–π (Daria)"
    voice_status = f"üé§ –ì–æ–ª–æ—Å: {voice_lang}"
    
    limits_info = ""
    if MODEL_LIMITS:
        limits_info = "\n\nüìä –ò—Å—á–µ—Ä–ø–∞–Ω–æ:\n"
        for model, apis in MODEL_LIMITS.items():
            exhausted = [f"#{k+1}" for k, v in apis.items() if v]
            if exhausted:
                limits_info += f"  ‚Ä¢ {model}: {', '.join(exhausted)}\n"
    
    commands_info = "\n\nüìã –ö–æ–º–∞–Ω–¥—ã:\n/az - –ê–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å\n/ru - –†—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å\n/banan [prompt] - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Ä—Ç–∏–Ω–∫–∏"
    
    await message.answer(f"ü§ñ **Bot Ready**\n{status}\n{voice_status}{commands_info}{limits_info}")

@dp.message(Command("az"))
async def switch_to_az_handler(message: Message):
    """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å"""
    global CURRENT_VOICE
    CURRENT_VOICE = "az"
    await message.answer("üé§ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª—Å—è –Ω–∞ –∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å (Banu)")

@dp.message(Command("ru"))
async def switch_to_ru_handler(message: Message):
    """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å"""
    global CURRENT_VOICE
    CURRENT_VOICE = "ru"
    await message.answer("üé§ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª—Å—è –Ω–∞ —Ä—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å (Daria)")

@dp.message(Command("banan"))
async def banan_handler(message: Message):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Ä—Ç–∏–Ω–∫–∏ —á–µ—Ä–µ–∑ nanobana"""
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã
    command_text = message.text.replace("/banan", "").strip()
    
    if not command_text:
        await message.answer("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /banan [–æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏]")
        return
    
    await message.answer("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É...")
    
    image_url = await generate_image_nanobana(command_text)
    
    if image_url:
        try:
            await message.answer_photo(
                photo=image_url,
                caption=f"‚úÖ –ì–æ—Ç–æ–≤–æ!\n\nPrompt: {command_text}"
            )
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏: {e}")
            await message.answer(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É.\n\nURL: {image_url}")
    else:
        await message.answer("‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏")

@dp.message()
async def main_handler(message: Message):
    global ACTIVE_MODEL, ACTIVE_MODEL_NAME
    
    if not ACTIVE_MODEL:
        status_msg = await message.answer("‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞...")
        if not await find_best_working_model(silent=True):
            if not await switch_api_key(silent=True):
                await status_msg.edit_text("‚ùå –õ–∏–º–∏—Ç—ã")
                return
        try:
            await status_msg.delete()
        except:
            pass
    
    bot_user = await bot.get_me()
    
    if not await is_addressed_to_bot(message, bot_user):
        return
    
    await bot.send_chat_action(chat_id=message.chat.id, action="record_voice")
    
    try:
        text_content = ""
        if message.text:
            text_content = message.text.replace(f"@{bot_user.username}", "").strip()
        elif message.caption:
            text_content = message.caption.replace(f"@{bot_user.username}", "").strip()
        
        print(f"\nüì® {text_content[:50]}...")
        
        prompt_parts, temp_files_to_delete = await prepare_prompt_parts(message, bot_user)
        
        if not prompt_parts:
            return
        
        await process_with_retry(message, bot_user, text_content, prompt_parts, temp_files_to_delete)
    
    except Exception as e:
        logging.error(f"Error: {e}")
        await message.reply("‚ùå –û—à–∏–±–∫–∞")

# --- SERVER ---
@app.get("/")
async def root():
    return {
        "status": "Alive",
        "model": ACTIVE_MODEL_NAME,
        "voice": VOICES[CURRENT_VOICE],
        "api": f"{CURRENT_API_KEY_INDEX + 1}/{len(GOOGLE_KEYS)}"
    }

@app.get("/health")
async def health_check():
    return {"status": "ok"}

async def keep_alive_ping():
    if not RENDER_URL:
        return
    while True:
        await asyncio.sleep(300)
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{RENDER_URL}/health") as resp:
                    pass
        except:
            pass

async def start_bot():
    global CURRENT_API_KEY_INDEX
    for i, key in enumerate(GOOGLE_KEYS):
        try:
            genai.configure(api_key=key)
            CURRENT_API_KEY_INDEX = i
            print(f"‚úÖ API #{i + 1}")
            break
        except:
            pass
    
    await find_best_working_model()
    await bot.delete_webhook(drop_pending_updates=True)
    await dp.start_polling(bot)

async def start_server():
    config = uvicorn.Config(app, host="0.0.0.0", port=10000, log_level="error")
    server = uvicorn.Server(config)
    await server.serve()

async def main():
    await asyncio.gather(start_server(), start_bot(), keep_alive_ping())

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass
