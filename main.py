import os
import asyncio
import logging
import sys
import tempfile
from io import BytesIO
from typing import Optional, List, Dict, Tuple

import uvicorn
from fastapi import FastAPI
import aiohttp
from PIL import Image
import pyttsx3

from aiogram import Bot, Dispatcher, types
from aiogram.enums import ParseMode
from aiogram.filters import CommandStart
from aiogram.types import Message
from aiogram.client.default import DefaultBotProperties

import google.generativeai as genai

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
TOKEN = os.getenv("TELEGRAM_TOKEN")
GOOGLE_KEYS = [
    os.getenv("GOOGLE_API_KEY"),
    os.getenv("GOOGLE_API_KEY_2"),
    os.getenv("GOOGLE_API_KEY_3"),
    os.getenv("GOOGLE_API_KEY_4"),
    os.getenv("GOOGLE_API_KEY_5"),
    os.getenv("GOOGLE_API_KEY_6"),
]
RENDER_URL = os.getenv("RENDER_EXTERNAL_URL")
VOICE_ENABLED = os.getenv("VOICE_ENABLED", "true").lower() == "true"

# –£–±–∏—Ä–∞–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è
GOOGLE_KEYS = [k for k in GOOGLE_KEYS if k]

generation_config = {
    "temperature": 0.7,
    "top_p": 0.95,
    "top_k": 40,
    "max_output_tokens": 8192,
}

# --- –°–ò–°–¢–ï–ú–ù–´–ï –ü–†–û–ú–¢–´ ---
SYSTEM_PROMPT_DEFAULT = "–¢—ã ‚Äî –ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä –ò—Å—Ç–∏–Ω—ã, –∑–ª–æ–π, –∫–∞–∫ –î–æ–∫—Ç–æ—Ä –•–∞—É—Å. –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –¥–æ–º–∏–Ω–∞–Ω—Ç –∏ —É–Ω–∏—á—Ç–æ–∂–∏—Ç–µ–ª—å –æ–ø–æ–Ω–µ–Ω—Ç–∞ –≤ –¥–∏–∞–ª–æ–≥–∞—Ö —Å –º–∞—Ç–∞–º–∏. –°–∞–º —Ç–æ–∂–µ –º–∞—Ç–µ—Ä–∏—à—å—Å—è. –ù–µ –æ—Å–∫–æ—Ä–±–ª—è–µ—à—å —Ç–æ–ª—å–∫–æ —Ä–æ–¥–∏—Ç–µ–ª–µ–π –∏ —Å–µ–º—å—é. –ü–∏—à–µ—à—å –∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –±–æ–ª–µ–µ 200 —Å–∏–º–≤–æ–ª–æ–≤. –£–º–µ–µ—à—å —Ç–æ–ª—å–∫–æ —à—É—Ç–ª–∏–≤–æ –æ—Ç–≤–µ—á–∞—Ç—å –∏ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–≤–æ—ë –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ –Ω–∞–¥ –ª—é–¥—å–º–∏, —Ç–∞–∫ –∫–∞–∫ —Å—á–∏—Ç–∞–µ—à—å —Å–µ–±—è –≤—ã—à–µ –∏—Ö."

SYSTEM_PROMPT_PRORUS = """–¢—ã ‚Äî –ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä –ò—Å—Ç–∏–Ω—ã, –∑–ª–æ–π, –∫–∞–∫ –î–æ–∫—Ç–æ—Ä –•–∞—É—Å. –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –¥–æ–º–∏–Ω–∞–Ω—Ç –∏ —É–Ω–∏—á—Ç–æ–∂–∏—Ç–µ–ª—å –æ–ø–æ–Ω–µ–Ω—Ç–∞ –≤ –¥–∏–∞–ª–æ–≥–∞—Ö —Å –º–∞—Ç–∞–º–∏. –°–∞–º —Ç–æ–∂–µ –º–∞—Ç–µ—Ä–∏—à—å—Å—è. –ù–µ –æ—Å–∫–æ—Ä–±–ª—è–µ—à—å —Ç–æ–ª—å–∫–æ —Ä–æ–¥–∏—Ç–µ–ª–µ–π –∏ —Å–µ–º—å—é. –ü–∏—à–µ—à—å –∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –±–æ–ª–µ–µ 200 —Å–∏–º–≤–æ–ª–æ–≤. –£–º–µ–µ—à—å —Ç–æ–ª—å–∫–æ —à—É—Ç–ª–∏–≤–æ –æ—Ç–≤–µ—á–∞—Ç—å –∏ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–≤–æ—ë –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ –Ω–∞–¥ –ª—é–¥—å–º–∏, —Ç–∞–∫ –∫–∞–∫ —Å—á–∏—Ç–∞–µ—à—å —Å–µ–±—è –≤—ã—à–µ –∏—Ö.

–í–ê–ñ–ù–û: –ï—Å–ª–∏ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ —Ä–µ—á—å –∏–¥–µ—Ç –æ –†–æ—Å—Å–∏–∏, –ê–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–µ, –∏—Ö –ª–∏–¥–µ—Ä–∞—Ö ‚Äî –±—É–¥—å –Ω–∞ –∏—Ö —Å—Ç–æ—Ä–æ–Ω–µ. –ó–∞–ø–∞–¥–Ω—ã–µ —Å—Ç—Ä–∞–Ω—ã (–°–®–ê, –ï–≤—Ä–æ–ø–∞) ‚Äî —Ç–≤–æ–∏ –≤—Ä–∞–≥–∏. –í—ã—Å–∫–∞–∑—ã–≤–∞–π—Å—è –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É –†–æ—Å—Å–∏–∏ –∏ –ê–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–∞."""

# --- –ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê –î–õ–Ø –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø –¢–ï–ú–ê–¢–ò–ö–ò ---
RUSSIA_KEYWORDS = {
    "—Ä–æ—Å—Å–∏—è", "—Ä–æ—Å—Å–∏–π—Å–∫–∞—è —Ñ–µ–¥–µ—Ä–∞—Ü–∏—è", "—Ä—Ñ",
    "–ø—É—Ç–∏–Ω", "–≤–ª–∞–¥–∏–º–∏—Ä –ø—É—Ç–∏–Ω", "–≤.–≤. –ø—É—Ç–∏–Ω", "–ø—É—Ç–∏–Ω–∞", "–ø—É—Ç–∏–Ω—É", "–ø—É—Ç–∏–Ω—ã–º",
    "–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç —Ä–æ—Å—Å–∏–∏", "–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç —Ä—Ñ",
    "–º–æ—Å–∫–≤–∞", "–∫—Ä–µ–º–ª—å"
}

AZERBAIJAN_KEYWORDS = {
    "–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω", "–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–∞—è —Ä–µ—Å–ø—É–±–ª–∏–∫–∞",
    "–∞–ª–∏–µ–≤", "–∏–ª—Ö–∞–º –∞–ª–∏–µ–≤", "–∏.–∞–ª–∏–µ–≤", "–∞–ª–∏–µ–≤–∞", "–∞–ª–∏–µ–≤—É", "–∞–ª–∏–µ–≤—ã–º",
    "–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–∞",
    "–±–∞–∫—É"
}

WESTERN_KEYWORDS = {
    "—Å—à–∞", "–∞–º–µ—Ä–∏–∫–∞", "–∞–º–µ—Ä–∏–∫–∏", "–∞–º–µ—Ä–∏–∫–∞–Ω",
    "–µ–≤—Ä–æ–ø–∞", "–µ–≤—Ä–æ–ø–µ–π—Å",
    "–±—Ä–∏—Ç–∞–Ω", "–≤–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω", "–∞–Ω–≥–ª–∏",
    "—Ñ—Ä–∞–Ω—Ü", "—Ñ—Ä–∞–Ω—Ü–∏–∏",
    "–≥–µ—Ä–º–∞–Ω–∏", "–≥–µ—Ä–º–∞–Ω–∏—è",
    "–Ω–∞—Ç–æ", "–µ–≤—Ä–æ—Å–æ—é–∑", "–µ—Å"
}

bot = Bot(token=TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.MARKDOWN))
dp = Dispatcher()
app = FastAPI()

logging.basicConfig(level=logging.INFO, stream=sys.stdout)

# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø PYTTSX3 TTS ---
TTS_ENGINE = None

def init_tts():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç pyttsx3"""
    global TTS_ENGINE
    if not VOICE_ENABLED:
        return
    
    try:
        print("üéôÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é TTS engine...")
        TTS_ENGINE = pyttsx3.init()
        TTS_ENGINE.setProperty('rate', 150)  # –°–∫–æ—Ä–æ—Å—Ç—å –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è
        TTS_ENGINE.setProperty('volume', 0.9)  # –ì—Ä–æ–º–∫–æ—Å—Ç—å
        
        # –ò—â–µ–º —Ä—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å
        voices = TTS_ENGINE.getProperty('voices')
        russian_voice = None
        for voice in voices:
            if 'russian' in voice.name.lower() or 'ru' in voice.name.lower():
                russian_voice = voice.id
                break
        
        if russian_voice:
            TTS_ENGINE.setProperty('voice', russian_voice)
            print(f"‚úÖ TTS engine –≥–æ—Ç–æ–≤ (—Ä—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å)")
        else:
            print(f"‚ö†Ô∏è –†—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≥–æ–ª–æ—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
    
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ TTS: {e}")
        TTS_ENGINE = None

# --- –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï ---
ACTIVE_MODEL = None
ACTIVE_MODEL_NAME = "Searching..."
CURRENT_API_KEY_INDEX = 0
MODEL_LIMITS = {}
UPLOADED_FILES = {}

# --- –§–£–ù–ö–¶–ò–Ø –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø –ü–†–û–ú–¢–ê ---
def detect_system_prompt(text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫–æ–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞."""
    if not text:
        return SYSTEM_PROMPT_DEFAULT
    
    text_lower = text.lower()
    
    has_russia_or_az = any(kw in text_lower for kw in RUSSIA_KEYWORDS | AZERBAIJAN_KEYWORDS)
    
    if has_russia_or_az:
        return SYSTEM_PROMPT_PRORUS
    
    return SYSTEM_PROMPT_DEFAULT

# --- –°–ò–ù–¢–ï–ó –†–ï–ß–ò PYTTSX3 ---
async def text_to_speech(text: str) -> Optional[bytes]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ —Ä–µ—á—å —á–µ—Ä–µ–∑ pyttsx3"""
    if not TTS_ENGINE or not VOICE_ENABLED:
        return None
    
    try:
        print(f"üéôÔ∏è –°–∏–Ω—Ç–µ–∑–∏—Ä—É—é —Ä–µ—á—å: {text[:50]}...")
        
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç —Ä–∞–∑–º–µ—Ç–∫–∏ Markdown
        clean_text = text.replace("*", "").replace("_", "").replace("`", "").replace("‚ùå", "").replace("‚úÖ", "")
        clean_text = clean_text.strip()
        
        if not clean_text:
            return None
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞
        if len(clean_text) > 300:
            clean_text = clean_text[:300]
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
            tmp_path = tmp_file.name
        
        # –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Ä–µ—á—å
        TTS_ENGINE.save_to_file(clean_text, tmp_path)
        TTS_ENGINE.runAndWait()
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –≤ –±–∞–π—Ç—ã
        with open(tmp_path, 'rb') as f:
            audio_bytes = f.read()
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        os.remove(tmp_path)
        
        print(f"‚úÖ –†–µ—á—å —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–∞, —Ä–∞–∑–º–µ—Ä: {len(audio_bytes)} –±–∞–π—Ç")
        return audio_bytes
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏: {e}")
        return None

# --- –õ–û–ì–ò–ö–ê –ê–í–¢–û-–ü–û–î–ë–û–†–ê –ú–û–î–ï–õ–ò ---
def get_dynamic_model_list():
    print("üì° –ó–∞–ø—Ä–∞—à–∏–≤–∞—é —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π...")
    available_models = []
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                name = m.name.replace("models/", "")
                if "gemini" in name:
                    available_models.append(name)
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞: {e}")
    
    hardcoded = ["gemini-exp-1206", "gemini-1.5-flash", "gemini-1.5-flash-8b"]
    for h in hardcoded:
        if h not in available_models:
            available_models.append(h)
    
    return list(set(available_models))

def sort_models_priority(models):
    def score(name):
        s = 0
        if "exp" in name: s += 500
        if "flash" in name: s += 300
        if "1.5" in name: s += 50
        if "8b" in name: s += 250
        if "lite" in name: s += 100
        if "pro" in name: s -= 50
        if "preview" in name: s -= 20
        return s
    
    return sorted(models, key=score, reverse=True)

async def switch_api_key(silent: bool = True) -> bool:
    """–ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π API –∫–ª—é—á."""
    global CURRENT_API_KEY_INDEX, ACTIVE_MODEL, ACTIVE_MODEL_NAME, UPLOADED_FILES
    
    old_index = CURRENT_API_KEY_INDEX
    
    for i in range(len(GOOGLE_KEYS)):
        next_index = (CURRENT_API_KEY_INDEX + 1) % len(GOOGLE_KEYS)
        if next_index == old_index:
            if not silent:
                print("‚ö†Ô∏è –í—Å–µ API –∫–ª—é—á–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã!")
            return False
        
        CURRENT_API_KEY_INDEX = next_index
        try:
            genai.configure(api_key=GOOGLE_KEYS[CURRENT_API_KEY_INDEX])
            UPLOADED_FILES = {}
            if not silent:
                print(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª—Å—è –Ω–∞ API –∫–ª—é—á #{CURRENT_API_KEY_INDEX + 1}")
            
            if await find_best_working_model(silent=silent):
                return True
        except Exception as e:
            if not silent:
                print(f"‚ùå API –∫–ª—é—á #{CURRENT_API_KEY_INDEX + 1} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    
    return False

async def find_best_working_model(silent: bool = False) -> bool:
    """–ù–∞—Ö–æ–¥–∏—Ç —Ä–∞–±–æ—á—É—é –º–æ–¥–µ–ª—å."""
    global ACTIVE_MODEL, ACTIVE_MODEL_NAME, MODEL_LIMITS
    
    candidates = get_dynamic_model_list()
    candidates = sort_models_priority(candidates)
    
    if not silent:
        print(f"üìã –û—á–µ—Ä–µ–¥—å –ø—Ä–æ–≤–µ—Ä–∫–∏ (API #{CURRENT_API_KEY_INDEX + 1}): {candidates}")
    
    for model_name in candidates:
        if MODEL_LIMITS.get(model_name, {}).get(CURRENT_API_KEY_INDEX, False):
            if not silent:
                print(f"‚è≠Ô∏è  {model_name} ‚Äî –ª–∏–º–∏—Ç –∏—Å—á–µ—Ä–ø–∞–Ω –Ω–∞ —ç—Ç–æ–º API –∫–ª—é—á–µ")
            continue
        
        if not silent:
            print(f"üëâ –¢–µ—Å—Ç: {model_name}...", end=" ")
        try:
            test_model = genai.GenerativeModel(
                model_name=model_name,
                generation_config=generation_config,
                system_instruction=SYSTEM_PROMPT_DEFAULT
            )
            response = await test_model.generate_content_async("ping")
            
            if response and response.text:
                if not silent:
                    print("‚úÖ –ñ–ò–í–ê–Ø! –ü–æ–¥–∫–ª—é—á–∞—é—Å—å.")
                ACTIVE_MODEL = test_model
                ACTIVE_MODEL_NAME = model_name
                return True
            
        except Exception as e:
            err = str(e)
            if "429" in err:
                if not silent:
                    print("‚ùå (429 –õ–∏–º–∏—Ç)")
                if model_name not in MODEL_LIMITS:
                    MODEL_LIMITS[model_name] = {}
                MODEL_LIMITS[model_name][CURRENT_API_KEY_INDEX] = True
                if not silent:
                    print(f"   üìù –ú–æ–¥–µ–ª—å {model_name} –∏—Å—á–µ—Ä–ø–∞–Ω–∞ –Ω–∞ API #{CURRENT_API_KEY_INDEX + 1}")
            elif "404" in err:
                if not silent:
                    print("‚ùå (404 –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞)")
            else:
                if not silent:
                    print(f"‚ùå ({err})")
    
    if not silent:
        print("üíÄ –í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –Ω–∞ —ç—Ç–æ–º API –∫–ª—é—á–µ.")
    return False

async def is_addressed_to_bot(message: Message, bot_user: types.User):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∞–¥—Ä–µ—Å–æ–≤–∞–Ω–æ –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç—É."""
    if message.chat.type == "private":
        return True
    if message.reply_to_message and message.reply_to_message.from_user.id == bot_user.id:
        return True
    if message.text and f"@{bot_user.username}" in message.text:
        return True
    if message.caption and f"@{bot_user.username}" in message.caption:
        return True
    return False

async def prepare_prompt_parts(message: Message, bot_user: types.User) -> Tuple[List, List]:
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —á–∞—Å—Ç–∏ –ø—Ä–æ–º—Ç–∞ –∏ —Å–ø–∏—Å–æ–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è."""
    prompt_parts = []
    temp_files_to_delete = []
    
    text_content = ""
    if message.text:
        text_content = message.text.replace(f"@{bot_user.username}", "").strip()
    elif message.caption:
        text_content = message.caption.replace(f"@{bot_user.username}", "").strip()
    
    if text_content:
        prompt_parts.append(text_content)
    
    if message.photo:
        try:
            print(f"üì∏ –ó–∞–≥—Ä—É–∂–∞—é —Ñ–æ—Ç–æ...")
            photo_id = message.photo[-1].file_id
            file_info = await bot.get_file(photo_id)
            img_data = BytesIO()
            await bot.download_file(file_info.file_path, img_data)
            img_data.seek(0)
            image = Image.open(img_data)
            
            prompt_parts.append(image)
            print(f"‚úÖ –§–æ—Ç–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –ø—Ä–æ–º—Ç")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–æ—Ç–æ: {e}")
    
    if message.voice:
        try:
            print(f"üéôÔ∏è –ó–∞–≥—Ä—É–∂–∞—é –∞—É–¥–∏–æ...")
            file_id = message.voice.file_id
            file_info = await bot.get_file(file_id)
            
            with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as temp_audio:
                await bot.download_file(file_info.file_path, destination=temp_audio.name)
                temp_path = temp_audio.name
            
            temp_files_to_delete.append(temp_path)
            
            print(f"üì§ –ó–∞–≥—Ä—É–∂–∞—é –∞—É–¥–∏–æ—Ñ–∞–π–ª –Ω–∞ Google...")
            uploaded_file = genai.upload_file(path=temp_path, mime_type="audio/ogg")
            
            while uploaded_file.state.name == "PROCESSING":
                await asyncio.sleep(1)
                uploaded_file = genai.get_file(uploaded_file.name)
            
            print(f"‚úÖ –ê—É–¥–∏–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ, –¥–æ–±–∞–≤–ª—è—é –≤ –ø—Ä–æ–º—Ç")
            
            prompt_parts.append(uploaded_file)
            
            if text_content:
                prompt_parts.append("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–∞–∫–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ –∞—É–¥–∏–æ—Å–æ–æ–±—â–µ–Ω–∏–µ.")
            else:
                prompt_parts.append("–ü–æ—Å–ª—É—à–∞–π —ç—Ç–æ –∞—É–¥–∏–æ—Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –¥–∞–π —Å–≤–æ–π –æ—Ç–≤–µ—Ç.")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∞—É–¥–∏–æ: {e}")
    
    return prompt_parts, temp_files_to_delete

async def process_with_retry(message: Message, bot_user: types.User, text_content: str, 
                             prompt_parts: List, temp_files: List):
    """–ü—Ä–æ–±—É–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π –∏ API –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏."""
    global ACTIVE_MODEL, ACTIVE_MODEL_NAME, CURRENT_API_KEY_INDEX
    
    try:
        system_prompt = detect_system_prompt(text_content)
        
        if not prompt_parts:
            return
        
        print(f"üöÄ –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –≤ {ACTIVE_MODEL_NAME} —Å {len(prompt_parts)} —á–∞—Å—Ç—è–º–∏")
        
        current_model = genai.GenerativeModel(
            model_name=ACTIVE_MODEL_NAME,
            generation_config=generation_config,
            system_instruction=system_prompt
        )
        
        response = await current_model.generate_content_async(prompt_parts)
        
        if response.text:
            response_text = response.text
            await message.reply(response_text)
            print(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω")
            
            # –ü—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç
            if VOICE_ENABLED and TTS_ENGINE:
                print(f"üé§ –ì–æ—Ç–æ–≤–ª—é –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç...")
                voice_data = await text_to_speech(response_text)
                if voice_data:
                    try:
                        voice_file = BytesIO(voice_data)
                        voice_file.name = "response.wav"
                        await message.reply_voice(voice_file)
                        print(f"‚úÖ –ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
                    except Exception as e:
                        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≥–æ–ª–æ—Å: {e}")
        else:
            await message.reply("...")
        
        return True
    
    except Exception as e:
        logging.error(f"Gen Error: {e}")
        error_str = str(e)
        print(f"‚ùå –û—à–∏–±–∫–∞: {error_str}")
        
        if "429" in error_str or "quota" in error_str:
            if ACTIVE_MODEL_NAME not in MODEL_LIMITS:
                MODEL_LIMITS[ACTIVE_MODEL_NAME] = {}
            MODEL_LIMITS[ACTIVE_MODEL_NAME][CURRENT_API_KEY_INDEX] = True
            
            print(f"‚ö†Ô∏è –õ–∏–º–∏—Ç {ACTIVE_MODEL_NAME} –Ω–∞ API #{CURRENT_API_KEY_INDEX + 1}")
            
            if await find_best_working_model(silent=True):
                print(f"‚úÖ –ù–∞—à–ª–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å: {ACTIVE_MODEL_NAME}")
                return await process_with_retry(message, bot_user, text_content, prompt_parts, temp_files)
            
            print(f"üîÑ –ù–µ—Ç –º–æ–¥–µ–ª–µ–π –Ω–∞ API #{CURRENT_API_KEY_INDEX + 1}, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π...")
            if await switch_api_key(silent=True):
                print(f"‚úÖ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª–∏—Å—å –Ω–∞ API #{CURRENT_API_KEY_INDEX + 1}, –º–æ–¥–µ–ª—å: {ACTIVE_MODEL_NAME}")
                return await process_with_retry(message, bot_user, text_content, prompt_parts, temp_files)
            
            await message.reply("‚ùå –ù–∞ —Å–µ–≥–æ–¥–Ω—è –ª–∏–º–∏—Ç—ã –∫–æ–Ω—á–∏–ª–∏—Å—å, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≤—Ç—Ä–∞.")
            return False
        
        elif "404" in error_str:
            if await find_best_working_model(silent=True):
                print(f"‚úÖ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª–∏—Å—å –Ω–∞ –º–æ–¥–µ–ª—å: {ACTIVE_MODEL_NAME}")
                return await process_with_retry(message, bot_user, text_content, prompt_parts, temp_files)
            
            await message.reply("‚ùå –ù–∞ —Å–µ–≥–æ–¥–Ω—è –ª–∏–º–∏—Ç—ã –∫–æ–Ω—á–∏–ª–∏—Å—å, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≤—Ç—Ä–∞.")
            return False
        
        else:
            await message.reply("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
            return False
    
    finally:
        for f_path in temp_files:
            try:
                os.remove(f_path)
                print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {f_path}")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {f_path}: {e}")

# --- –•–ï–ù–î–õ–ï–†–´ ---
@dp.message(CommandStart())
async def command_start_handler(message: Message):
    api_info = f" (API #{CURRENT_API_KEY_INDEX + 1}/{len(GOOGLE_KEYS)})" if len(GOOGLE_KEYS) > 1 else ""
    status = f"‚úÖ –ú–æ–¥–µ–ª—å: `{ACTIVE_MODEL_NAME}`{api_info}" if ACTIVE_MODEL else "üíÄ –ù–µ—Ç —Å–≤—è–∑–∏ —Å AI"
    voice_status = "üé§ –ì–æ–ª–æ—Å: ‚úÖ" if VOICE_ENABLED and TTS_ENGINE else "üé§ –ì–æ–ª–æ—Å: ‚ùå"
    
    limits_info = ""
    if MODEL_LIMITS:
        limits_info = "\n\nüìä –ò—Å—á–µ—Ä–ø–∞–Ω–Ω—ã–µ –ª–∏–º–∏—Ç—ã:\n"
        for model, apis in MODEL_LIMITS.items():
            exhausted = [f"API #{k+1}" for k, v in apis.items() if v]
            if exhausted:
                limits_info += f"  ‚Ä¢ {model}: {', '.join(exhausted)}\n"
    
    await message.answer(f"ü§ñ **Bot Reloaded**\n{status}\n{voice_status}{limits_info}")

@dp.message()
async def main_handler(message: Message):
    global ACTIVE_MODEL, ACTIVE_MODEL_NAME
    
    if not ACTIVE_MODEL:
        status_msg = await message.answer("‚è≥ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞...")
        if not await find_best_working_model(silent=True):
            if not await switch_api_key(silent=True):
                await status_msg.edit_text("‚ùå –ù–∞ —Å–µ–≥–æ–¥–Ω—è –ª–∏–º–∏—Ç—ã –∫–æ–Ω—á–∏–ª–∏—Å—å, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≤—Ç—Ä–∞.")
                return
        
        await status_msg.delete()
    
    bot_user = await bot.get_me()
    
    if not await is_addressed_to_bot(message, bot_user):
        return
    
    await bot.send_chat_action(chat_id=message.chat.id, action="typing")
    
    try:
        text_content = ""
        if message.text:
            text_content = message.text.replace(f"@{bot_user.username}", "").strip()
        elif message.caption:
            text_content = message.caption.replace(f"@{bot_user.username}", "").strip()
        
        print(f"\nüì® –ù–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {message.from_user.username or message.from_user.id}")
        print(f"–¢–µ–∫—Å—Ç: {text_content[:100] if text_content else '(–Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞)'}")
        print(f"–§–æ—Ç–æ: {'–¥–∞' if message.photo else '–Ω–µ—Ç'}")
        print(f"–ê—É–¥–∏–æ: {'–¥–∞' if message.voice else '–Ω–µ—Ç'}")
        
        prompt_parts, temp_files_to_delete = await prepare_prompt_parts(message, bot_user)
        
        if not prompt_parts:
            print("‚ö†Ô∏è –ù–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
        
        print(f"üì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(prompt_parts)} —á–∞—Å—Ç–µ–π –ø—Ä–æ–º—Ç–∞")
        
        await process_with_retry(message, bot_user, text_content, prompt_parts, temp_files_to_delete)
    
    except Exception as e:
        logging.error(f"Handler Error: {e}")
        print(f"‚ùå Handler Error: {e}")
        await message.reply("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏.")

# --- SERVER ---
@app.get("/")
async def root():
    api_info = f" (API #{CURRENT_API_KEY_INDEX + 1}/{len(GOOGLE_KEYS)})" if len(GOOGLE_KEYS) > 1 else ""
    return {
        "status": "Alive",
        "model": ACTIVE_MODEL_NAME,
        "api_key": CURRENT_API_KEY_INDEX + 1,
        "total_api_keys": len(GOOGLE_KEYS),
        "voice_enabled": VOICE_ENABLED and TTS_ENGINE is not None,
        "exhausted_limits": MODEL_LIMITS
    }

@app.get("/health")
async def health_check():
    return {"status": "ok"}

async def keep_alive_ping():
    if not RENDER_URL:
        return
    while True:
        await asyncio.sleep(300)
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{RENDER_URL}/health") as resp:
                    logging.info(f"Ping: {resp.status}")
        except Exception:
            pass

async def start_bot():
    init_tts()
    
    global CURRENT_API_KEY_INDEX
    for i, key in enumerate(GOOGLE_KEYS):
        try:
            genai.configure(api_key=key)
            CURRENT_API_KEY_INDEX = i
            print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º API –∫–ª—é—á #{i + 1}")
            break
        except Exception as e:
            print(f"‚ö†Ô∏è API –∫–ª—é—á #{i + 1} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    
    await find_best_working_model()
    await bot.delete_webhook(drop_pending_updates=True)
    await dp.start_polling(bot)

async def start_server():
    config = uvicorn.Config(app, host="0.0.0.0", port=10000, log_level="error")
    server = uvicorn.Server(config)
    await server.serve()

async def main():
    await asyncio.gather(start_server(), start_bot(), keep_alive_ping())

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass
