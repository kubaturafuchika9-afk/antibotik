import os
import asyncio
import logging
import sys
import tempfile
from io import BytesIO

import uvicorn
from fastapi import FastAPI
import aiohttp
from PIL import Image

from aiogram import Bot, Dispatcher, types
from aiogram.enums import ParseMode
from aiogram.filters import CommandStart
from aiogram.types import Message
from aiogram.client.default import DefaultBotProperties

import google.generativeai as genai

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
TOKEN = os.getenv("TELEGRAM_TOKEN")
GOOGLE_KEY = os.getenv("GOOGLE_API_KEY")
RENDER_URL = os.getenv("RENDER_EXTERNAL_URL")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Google Gemini
genai.configure(api_key=GOOGLE_KEY)

# --- üõ° –õ–û–ì–ò–ö–ê –ó–ê–©–ò–¢–´ (–ê–î–ê–ü–¢–ò–†–û–í–ê–ù–ù–ê–Ø –ü–û–î LITE) ---

# –ú—ã –≤—ã–Ω—É–∂–¥–µ–Ω—ã —Ä–∞–∑—Ä–µ—à–∏—Ç—å 2.0, –Ω–æ –¢–û–õ–¨–ö–û Lite –≤–µ—Ä—Å–∏—é.
# –û–±—ã—á–Ω–∞—è 2.0 Flash –∏–º–µ–µ—Ç –ª–∏–º–∏—Ç 0, –ø–æ—ç—Ç–æ–º—É –º—ã –µ—ë –±–∞–Ω–∏–º.
FORBIDDEN_KEYWORDS = [
    "latest",       # –ü–ª–∞–≤–∞—é—â–∏–π —Ç–µ–≥
    "gemini-2.5",   # –õ–∏–º–∏—Ç 20
    "gemini-3",     # –ë—É–¥—É—â–∏–µ
    "pro",          # –ú–∞–ª–æ –ª–∏–º–∏—Ç–æ–≤
    "ultra",        # –ü–ª–∞—Ç–Ω–æ
    "exp"           # –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ (–Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ)
]

# –ù–∞—à–∞ –Ω–æ–≤–∞—è —Ü–µ–ª—å - Lite –≤–µ—Ä—Å–∏—è
SAFE_MODEL = "gemini-2.0-flash-lite-001"

# –ú–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä—É—é –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º
REQUESTED_MODEL = "gemini-2.0-flash-lite-001"

def get_safe_model_name(requested: str) -> str:
    # 1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —è–≤–Ω—ã–π –∑–∞–ø—Ä–µ—Ç —Å–ª–æ–≤
    for ban_word in FORBIDDEN_KEYWORDS:
        if ban_word in requested:
            print(f"üõ° –ë–õ–û–ö–ò–†–û–í–ö–ê: –ú–æ–¥–µ–ª—å '{requested}' —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–ø—Ä–µ—â–µ–Ω–Ω–æ–µ —Å–ª–æ–≤–æ '{ban_word}'.")
            return SAFE_MODEL
    
    # 2. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞: –ï—Å–ª–∏ —ç—Ç–æ 2.0, —Ç–æ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å Lite
    if "gemini-2.0" in requested and "lite" not in requested:
        print(f"üõ° –ë–õ–û–ö–ò–†–û–í–ö–ê: –û–±—ã—á–Ω–∞—è –≤–µ—Ä—Å–∏—è 2.0 –∏–º–µ–µ—Ç –ø–ª–æ—Ö–∏–µ –ª–∏–º–∏—Ç—ã. –ü–µ—Ä–µ–∫–ª—é—á–∞—é –Ω–∞ Lite.")
        return SAFE_MODEL

    return requested

# –ò—Ç–æ–≥–æ–≤–∞—è –º–æ–¥–µ–ª—å
FINAL_MODEL_ID = get_safe_model_name(REQUESTED_MODEL)

print(f"‚úÖ –ó–ê–ü–£–°–ö –ù–ê –ú–û–î–ï–õ–ò: {FINAL_MODEL_ID}")

# --- –ù–ê–°–¢–†–û–ô–ö–ê GEMINI ---
generation_config = {
  "temperature": 0.7,
  "top_p": 0.95,
  "top_k": 40,
  "max_output_tokens": 8192,
}

model = genai.GenerativeModel(
  model_name=FINAL_MODEL_ID,
  generation_config=generation_config,
  system_instruction="–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –≤ Telegram. –¢—ã —É–º–µ–µ—à—å —Å–ª—É—à–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤—ã–µ –∏ —Å–º–æ—Ç—Ä–µ—Ç—å —Ñ–æ—Ç–æ. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –µ–º–∫–æ –∏ —Å —é–º–æ—Ä–æ–º."
)

# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ë–û–¢–ê ---
bot = Bot(
    token=TOKEN, 
    default=DefaultBotProperties(parse_mode=ParseMode.MARKDOWN)
)
dp = Dispatcher()
app = FastAPI()

logging.basicConfig(level=logging.INFO, stream=sys.stdout)

# --- –õ–û–ì–ò–ö–ê ---

async def is_addressed_to_bot(message: Message, bot_user: types.User):
    if message.chat.type == "private":
        return True
    if message.reply_to_message and message.reply_to_message.from_user.id == bot_user.id:
        return True
    if message.text and f"@{bot_user.username}" in message.text:
        return True
    if message.caption and f"@{bot_user.username}" in message.caption:
        return True
    return False

# --- –•–ï–ù–î–õ–ï–†–´ ---

@dp.message(CommandStart())
async def command_start_handler(message: Message):
    await message.answer(
        f"üõ° **System Online**\n"
        f"Model: `{FINAL_MODEL_ID}`\n"
        f"Status: **Lite Mode**\n\n"
        f"–ü—Ä–∏–≤–µ—Ç! 1.5 R.I.P., –ø—Ä–æ–±—É–µ–º Lite –≤–µ—Ä—Å–∏—é."
    )

@dp.message()
async def main_handler(message: Message):
    bot_user = await bot.get_me()
    
    if not await is_addressed_to_bot(message, bot_user):
        return

    await bot.send_chat_action(chat_id=message.chat.id, action="typing")

    prompt_parts = [] 
    temp_files_to_delete = []

    try:
        # –¢–ï–ö–°–¢
        text_content = ""
        if message.text:
            text_content = message.text.replace(f"@{bot_user.username}", "").strip()
        elif message.caption:
            text_content = message.caption.replace(f"@{bot_user.username}", "").strip()
        
        if text_content:
            prompt_parts.append(text_content)

        # –§–û–¢–û
        if message.photo:
            photo_id = message.photo[-1].file_id
            file_info = await bot.get_file(photo_id)
            img_data = BytesIO()
            await bot.download_file(file_info.file_path, img_data)
            img_data.seek(0)
            image = Image.open(img_data)
            prompt_parts.append(image)

        # –ì–û–õ–û–°–û–í–û–ï
        if message.voice:
            file_id = message.voice.file_id
            file_info = await bot.get_file(file_id)
            with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as temp_audio:
                await bot.download_file(file_info.file_path, destination=temp_audio.name)
                temp_path = temp_audio.name
            temp_files_to_delete.append(temp_path)

            uploaded_file = genai.upload_file(path=temp_path, mime_type="audio/ogg")
            # –ñ–¥–µ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏
            while uploaded_file.state.name == "PROCESSING":
                await asyncio.sleep(1)
                uploaded_file = genai.get_file(uploaded_file.name)

            prompt_parts.append(uploaded_file)
            prompt_parts.append("–ü–æ—Å–ª—É—à–∞–π —ç—Ç–æ –∞—É–¥–∏–æ –∏ –æ—Ç–≤–µ—Ç—å.")

        if not prompt_parts:
            await message.reply("–Ø –Ω–µ –≤–∏–∂—É —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ.")
            return

        # –ì–ï–ù–ï–†–ê–¶–ò–Ø
        response = await model.generate_content_async(prompt_parts)
        
        if response.text:
            await message.reply(response.text)
        else:
            await message.reply("...")

    except Exception as e:
        logging.error(f"Error: {e}")
        err_text = str(e)
        
        if "429" in err_text:
             await message.reply(f"üíÄ –î–∞–∂–µ Lite –≤–µ—Ä—Å–∏—è –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–∞ (429). Google –∂–µ—Å—Ç–∏—Ç.")
        elif "404" in err_text:
             await message.reply("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        else:
             await message.reply("–û—à–∏–±–∫–∞ —Å–∏—Å—Ç–µ–º—ã.")
    
    finally:
        for f_path in temp_files_to_delete:
            try:
                os.remove(f_path)
            except:
                pass

# --- WEB SERVER ---

@app.get("/")
async def root():
    return {"status": "Alive", "model": FINAL_MODEL_ID}

@app.get("/health")
async def health_check():
    return {"status": "ok"}

async def keep_alive_ping():
    if not RENDER_URL:
        return
    while True:
        await asyncio.sleep(300)
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{RENDER_URL}/health") as resp:
                    logging.info(f"Ping: {resp.status}")
        except Exception:
            pass

async def start_bot():
    await bot.delete_webhook(drop_pending_updates=True)
    await dp.start_polling(bot)

async def start_server():
    config = uvicorn.Config(app, host="0.0.0.0", port=10000, log_level="error")
    server = uvicorn.Server(config)
    await server.serve()

async def main():
    await asyncio.gather(start_server(), start_bot(), keep_alive_ping())

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass
